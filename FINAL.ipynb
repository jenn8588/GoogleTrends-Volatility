{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#python -W ignore file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrends\n",
    "import datetime \n",
    "from datetime import timedelta\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def GT_1mon(kw_string,geography):\n",
    "    pytrend = TrendReq(hl=geography, tz=480, timeout=(100,25), retries=2, backoff_factor=1 , requests_args={'verify':False})\n",
    "    df = pd.DataFrame()\n",
    "    pytrend.build_payload(kw_list=[kw_string], cat=7, timeframe='today 1-m' , geo=geography, gprop='')\n",
    "    pytrend.interest_over_time().get(kw_string)\n",
    "    df=df.append(pytrend.interest_over_time())\n",
    "    try:\n",
    "        df = df.drop(\"isPartial\",axis=1)\n",
    "    except:\n",
    "        return df\n",
    "    else:\n",
    "        return df\n",
    "def GT_7day(kw_string,geography):\n",
    "    pytrend = TrendReq(hl=geography, tz=480, timeout=(100,25), retries=2, backoff_factor=1 , requests_args={'verify':False})\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    pytrend.build_payload(kw_list=[kw_string], cat=7, timeframe='now 7-d' , geo=geography, gprop='')\n",
    "    pytrend.interest_over_time().get(kw_string)\n",
    "    df = df.append(pytrend.interest_over_time())\n",
    "    #df.rename(transform_date , inplace =True)\n",
    "    df = df.groupby('date').apply(lambda x : x.mean())\n",
    "    try:\n",
    "        df = df.drop(\"isPartial\",axis=1)\n",
    "    except:\n",
    "        return df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metal'"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_keywords_collect_del.columns[GT_keywords_collect_del.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "The request failed: Google returned a response with code 429.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-521-07bd81ba4233>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist1\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGT_1mon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-434-d76670a93bdb>\u001b[0m in \u001b[0;36mGT_1mon\u001b[1;34m(kw_string, geography)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpytrend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrendReq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgeography\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackoff_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrequests_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'verify'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mpytrend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_payload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkw_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkw_string\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'today 1-m'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mgeo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgeography\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgprop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mpytrend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterest_over_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkw_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpytrend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterest_over_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytrends\\request.py\u001b[0m in \u001b[0;36mbuild_payload\u001b[1;34m(self, kw_list, cat, timeframe, geo, gprop)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'req'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'req'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;31m# get tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytrends\\request.py\u001b[0m in \u001b[0;36m_tokens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_METHOD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mtrim_chars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         )['widgets']\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# order of the json matters...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytrends\\request.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m                 \u001b[1;34m'The request failed: Google returned a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[1;34m'response with code {0}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                 response=response)\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     def build_payload(self, kw_list, cat=0, timeframe='today 5-y', geo='',\n",
      "\u001b[1;31mResponseError\u001b[0m: The request failed: Google returned a response with code 429."
     ]
    }
   ],
   "source": [
    "Outputs_all = pd.DataFrame()\n",
    "\n",
    "for i in range(0 , GT_keywords_collect_del.shape[1]-3) :\n",
    "    \n",
    "    GT_keywords_collect_del = pd.read_csv('GT_keywords_collect_del.csv')\n",
    "    GT_keywords_collect_del.drop(['Unnamed: 0'] , axis = 1 , inplace = True)\n",
    "    GT_name = GT_keywords_collect_del.columns[i]\n",
    "    list1 = GT_keywords_collect_del.iloc[:,i].dropna()\n",
    "    \n",
    "    ###抓取過去30日資料\n",
    "    sum=0\n",
    "    num=0\n",
    "    print(GT_keywords_collect_del.columns[i])\n",
    "    data = pd.DataFrame()\n",
    "    for j in list1 :\n",
    "        start_time = time.time()\n",
    "        df = GT_1mon(j,'')\n",
    "        end_time = time.time()\n",
    "        data = pd.concat([data,df],axis = 1)   \n",
    "\n",
    "        num+=1\n",
    "        sum+=round(end_time - start_time, 6)\n",
    "        print(\"Already Done (30 days) : \"+'{}'.format(round(num,0)))\n",
    "\n",
    "    ###抓取過去過去 7日的小時資料\n",
    "    sum=0\n",
    "    num=0\n",
    "    data1 = pd.DataFrame()\n",
    "    for j in list1 :\n",
    "        start_time = time.time()\n",
    "        df = GT_7day(j,'')\n",
    "        end_time = time.time()\n",
    "        data1 = pd.concat([data1,df],axis = 1)   \n",
    "\n",
    "        num+=1\n",
    "        sum+=round(end_time - start_time, 6)\n",
    "        print(\"Already Done (7 days) : \"+'{}'.format(round(num,0)))\n",
    "    \n",
    "    ##處理日資料，刪除周末資料\n",
    "    data = data.tail(10)\n",
    "    data['weekday'] = 0\n",
    "    for i in range(0 , data.shape[0]) :\n",
    "        data['weekday'][i] = data.index[i].weekday()\n",
    "    data = data[~data['weekday'].isin([5,6])]\n",
    "\n",
    "    ##處理小時資料，將每日 quantile 20% 刪除，算出每日平均GT，再刪除周末資料和今日資料(可能有一筆或兩筆)\n",
    "    data1.reset_index(inplace = True)\n",
    "    data1['date'] = data1['date'].map(lambda x : str(x).split(' ')[0])\n",
    "    data1 = data1.groupby('date').apply(lambda x : x[x > x.quantile(0.2)].mean())\n",
    "    data1.index = pd.to_datetime(data1.index)\n",
    "    data1['weekday'] = 0\n",
    "    for i in range(0 , data1.shape[0]) :\n",
    "        data1['weekday'][i] = data1.index[i].weekday()\n",
    "    data1 = data1[ ~data1['weekday'].isin([5,6]) ]\n",
    "    data1.drop(['weekday' , 'date'] , axis = 1 , inplace = True)\n",
    "    data1 = data1[data1.index != str(datetime.date.today())]\n",
    "\n",
    "    ##將每個關鍵字平均作為指標，把 30日和 7日重複的資料做比例的平均，來做為調整的 scale\n",
    "    data = data.mean(axis = 1)\n",
    "    data1 = data1.mean(axis = 1)\n",
    "    date1 = str(data1.head(1).index[0])[0:10]\n",
    "    date2 = str(data.tail(1).index[0])[0:10]\n",
    "    diff1 = data[date1:date2].diff().dropna(axis = 0)\n",
    "    diff2 = data1[date1:date2].diff().dropna(axis = 0 )\n",
    "    multiply = diff1/diff2\n",
    "    multiply = multiply.mean()\n",
    "\n",
    "    ##取出過去五日GT資料\n",
    "    GT_last5day = data1*multiply\n",
    "    GT_last5day\n",
    "\n",
    "    ##處理 MA3、 MA3_diff\n",
    "    GT_MA3 = GT_last5day.rolling(window = 3).mean()\n",
    "    GT_MA3_diff = GT_MA3.diff()\n",
    "    benchmark = pd.concat([GT_last5day , GT_MA3 , GT_MA3_diff] , axis = 1 )\n",
    "    benchmark.columns = ['GT_last5day','GT_MA3','GT_MA3_diff']\n",
    "    benchmark = benchmark.tail(1)\n",
    "\n",
    "    ##判斷 GT是否有過 benchmark\n",
    "    Outputs = pd.DataFrame()\n",
    "    if benchmark['GT_last5day'][0] >= 60 or ( benchmark['GT_MA3'][0] >= 20 and benchmark['GT_MA3_diff'][0] >= 10 ) :\n",
    "        Outputs[GT_name] = 1\n",
    "    else :\n",
    "        Outputs[GT_name] = 0\n",
    "    Outputs.index = benchmark.index + timedelta(days = 1)\n",
    "    Outputs_all = Outputs_all.append(Outputs,ignore_index=True)\n",
    "Outputs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outputs_all.fillna(method='bfill', inplace=True)\n",
    "Outputs_all = Outputs_all.head(1)\n",
    "Outputs_all.index = Outputs.index\n",
    "Outputs_all.to_csv('Outputs_sample(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "###抓取過去30日資料\n",
    "sum=0\n",
    "num=0\n",
    "data = pd.DataFrame()\n",
    "for i in list1 :\n",
    "    start_time = time.time()\n",
    "    df = GT_1mon(i,'')\n",
    "    end_time = time.time()\n",
    "    data = pd.concat([data,df],axis = 1)   \n",
    "\n",
    "    num+=1\n",
    "    sum+=round(end_time - start_time, 6)\n",
    "    print(\"Already Done : \"+'{}'.format(round(num,0)))\n",
    "    \n",
    "###抓取過去過去 7日的小時資料\n",
    "sum=0\n",
    "num=0\n",
    "data1 = pd.DataFrame()\n",
    "for i in list1 :\n",
    "    start_time = time.time()\n",
    "    df = GT_7day(i,'')\n",
    "    end_time = time.time()\n",
    "    data1 = pd.concat([data1,df],axis = 1)   \n",
    "\n",
    "    num+=1\n",
    "    sum+=round(end_time - start_time, 6)\n",
    "    print(\"Already Done : \"+'{}'.format(round(num,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##處理日資料，刪除周末資料\n",
    "data = data.tail(10)\n",
    "data['weekday'] = 0\n",
    "for i in range(0 , data.shape[0]) :\n",
    "    data['weekday'][i] = data.index[i].weekday()\n",
    "data = data[~data['weekday'].isin([5,6])]\n",
    "\n",
    "##處理小時資料，將每日 quantile 20% 刪除，算出每日平均GT，再刪除周末資料和今日資料(可能有一筆或兩筆)\n",
    "data1.reset_index(inplace = True)\n",
    "data1['date'] = data1['date'].map(lambda x : str(x).split(' ')[0])\n",
    "data1 = data1.groupby('date').apply(lambda x : x[x > x.quantile(0.2)].mean())\n",
    "data1.index = pd.to_datetime(data1.index)\n",
    "data1['weekday'] = 0\n",
    "for i in range(0 , data1.shape[0]) :\n",
    "    data1['weekday'][i] = data1.index[i].weekday()\n",
    "data1 = data1[ ~data1['weekday'].isin([5,6]) ]\n",
    "data1.drop(['weekday' , 'date'] , axis = 1 , inplace = True)\n",
    "data1 = data1[data1.index != str(datetime.date.today())]\n",
    "\n",
    "##將每個關鍵字平均作為指標，把 30日和 7日重複的資料做比例的平均，來做為調整的 scale\n",
    "data = data.mean(axis = 1)\n",
    "data1 = data1.mean(axis = 1)\n",
    "date1 = str(data1.head(1).index[0])[0:10]\n",
    "date2 = str(data.tail(1).index[0])[0:10]\n",
    "diff1 = data[date1:date2].diff().dropna(axis = 0)\n",
    "diff2 = data1[date1:date2].diff().dropna(axis = 0 )\n",
    "multiply = diff1/diff2\n",
    "multiply = multiply.mean()\n",
    "\n",
    "##取出過去五日GT資料\n",
    "GT_last5day = data1*multiply\n",
    "GT_last5day\n",
    "\n",
    "##處理 MA3、 MA3_diff\n",
    "GT_MA3 = GT_last5day.rolling(window = 3).mean()\n",
    "GT_MA3_diff = GT_MA3.diff()\n",
    "benchmark = pd.concat([GT_last5day , GT_MA3 , GT_MA3_diff] , axis = 1 )\n",
    "benchmark.columns = ['GT_last5day','GT_MA3','GT_MA3_diff']\n",
    "benchmark = benchmark.tail(1)\n",
    "\n",
    "##判斷 GT是否有過 benchmark\n",
    "Outputs = pd.DataFrame()\n",
    "if benchmark['GT_last5day'][0] >= 60 or ( benchmark['GT_MA3'][0] >= 20 and benchmark['GT_MA3_diff'][0] >= 10 ) :\n",
    "    Outputs[GT_name] = ['Volatility Signal']\n",
    "else :\n",
    "    Outputs[GT_name] = ['None Signal']\n",
    "Outputs.index = benchmark.index + timedelta(days = 1)\n",
    "Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##處理日資料，刪除周末資料\n",
    "data = data.tail(10)\n",
    "data['weekday'] = 0\n",
    "for i in range(0 , data.shape[0]) :\n",
    "    data['weekday'][i] = data.index[i].weekday()\n",
    "data = data[~data['weekday'].isin([5,6])]\n",
    "\n",
    "##處理小時資料，將每日 quantile 20% 刪除，算出每日平均GT，再刪除周末資料和今日資料(可能有一筆或兩筆)\n",
    "data1.reset_index(inplace = True)\n",
    "data1['date'] = data1['date'].map(lambda x : str(x).split(' ')[0])\n",
    "data1 = data1.groupby('date').apply(lambda x : x[x > x.quantile(0.2)].mean())\n",
    "data1.index = pd.to_datetime(data1.index)\n",
    "data1['weekday'] = 0\n",
    "for i in range(0 , data1.shape[0]) :\n",
    "    data1['weekday'][i] = data1.index[i].weekday()\n",
    "data1 = data1[ ~data1['weekday'].isin([5,6]) ]\n",
    "data1.drop(['weekday' , 'date'] , axis = 1 , inplace = True)\n",
    "data1 = data1[data1.index != str(datetime.date.today())]\n",
    "\n",
    "##將每個關鍵字平均作為指標，把 30日和 7日重複的資料做比例的平均，來做為調整的 scale\n",
    "data = data.mean(axis = 1)\n",
    "data1 = data1.mean(axis = 1)\n",
    "date1 = str(data1.head(1).index[0])[0:10]\n",
    "date2 = str(data.tail(1).index[0])[0:10]\n",
    "diff1 = data[date1:date2].diff().dropna(axis = 0)\n",
    "diff2 = data1[date1:date2].diff().dropna(axis = 0 )\n",
    "multiply = diff1/diff2\n",
    "multiply = multiply.mean()\n",
    "\n",
    "##取出過去五日GT資料\n",
    "GT_last5day = data1*multiply\n",
    "GT_last5day\n",
    "\n",
    "##處理 MA3、 MA3_diff\n",
    "GT_MA3 = GT_last5day.rolling(window = 3).mean()\n",
    "GT_MA3_diff = GT_MA3.diff()\n",
    "benchmark = pd.concat([GT_last5day , GT_MA3 , GT_MA3_diff] , axis = 1 )\n",
    "benchmark.columns = ['GT_last5day','GT_MA3','GT_MA3_diff']\n",
    "benchmark = benchmark.tail(1)\n",
    "\n",
    "##判斷 GT是否有過 benchmark\n",
    "Outputs = pd.DataFrame()\n",
    "if benchmark['GT_last5day'][0] >= 60 or ( benchmark['GT_MA3'][0] >= 20 and benchmark['GT_MA3_diff'][0] >= 10 ) :\n",
    "    Outputs[GT_name] = ['Volatility Signal']\n",
    "else :\n",
    "    Outputs[GT_name] = ['None Signal']\n",
    "Outputs.index = benchmark.index + timedelta(days = 1)\n",
    "Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##處理 MA3、 MA3_diff\n",
    "GT_MA3 = GT_last5day.rolling(window = 3).mean()\n",
    "GT_MA3_diff = GT_MA3.diff()\n",
    "benchmark = pd.concat([GT_last5day , GT_MA3 , GT_MA3_diff] , axis = 1 )\n",
    "benchmark.columns = ['GT_last5day','GT_MA3','GT_MA3_diff']\n",
    "benchmark = benchmark.tail(1)\n",
    "\n",
    "##判斷 GT是否有過 benchmark\n",
    "Outputs = pd.DataFrame()\n",
    "if benchmark['GT_last5day'][0] >= 60 or ( benchmark['GT_MA3'][0] >= 20 and benchmark['GT_MA3_diff'][0] >= 10 ) :\n",
    "    Outputs['TX'] = ['Volatility Signal']\n",
    "else :\n",
    "    Outputs['TX'] = ['None Signal']\n",
    "Outputs.index = benchmark.index + timedelta(days = 1)\n",
    "Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs = pd.DataFrame()\n",
    "if benchmark['GT_last5day'][0] >= 60 or ( benchmark['GT_MA3'][0] >= 20 and benchmark['GT_MA3_diff'][0] >= 10 ) :\n",
    "    Outputs['TX'] = ['Volatility Signal']\n",
    "else :\n",
    "    Outputs['TX'] = ['None Signal']\n",
    "Outputs.index = benchmark.index + timedelta(days = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = data.tail(10)\n",
    "data['weekday'] = 0\n",
    "for i in range(0 , data.shape[0]) :\n",
    "    data['weekday'][i] = data.index[i].weekday()\n",
    "data = data[~data['weekday'].isin([5,6])]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data1.reset_index(inplace = True)\n",
    "data1['date'] = data1['date'].map(lambda x : str(x).split(' ')[0])\n",
    "data1 = data1.groupby('date').apply(lambda x : x[x > x.quantile(0.2)].mean())\n",
    "data1.index = pd.to_datetime(data1.index)\n",
    "data1['weekday'] = 0\n",
    "for i in range(0 , data1.shape[0]) :\n",
    "    data1['weekday'][i] = data1.index[i].weekday()\n",
    "data1 = data1[ ~data1['weekday'].isin([5,6]) ]\n",
    "data1.drop(['weekday' , 'date'] , axis = 1 , inplace = True)\n",
    "data1 = data1[data1.index != str(datetime.date.today())]\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = data.mean(axis = 1)\n",
    "data1 = data1.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = data.mean(axis = 1)\n",
    "data1 = data1.mean(axis = 1)\n",
    "date1 = str(data1.head(1).index[0])[0:10]\n",
    "date2 = str(data.tail(1).index[0])[0:10]\n",
    "diff1 = data[date1:date2].diff().dropna(axis = 0)\n",
    "diff2 = data1[date1:date2].diff().dropna(axis = 0 )\n",
    "multiply = diff1/diff2\n",
    "multiply = multiply.mean()\n",
    "multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GT_last5day = data1*multiply\n",
    "GT_last5day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "sum=0\n",
    "num=0\n",
    "data1 = pd.DataFrame()\n",
    "for i in list1 :\n",
    "    start_time = time.time()\n",
    "    df = GT_7day(i,'')\n",
    "    end_time = time.time()\n",
    "    data1 = pd.concat([data1,df],axis = 1)   \n",
    "\n",
    "    num+=1\n",
    "    sum+=round(end_time - start_time, 6)\n",
    "    print(\"Already Done : \"+'{}'.format(round(num,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##全部\n",
    "data_all = pd.DataFrame()\n",
    "start_time_all = time.time()\n",
    "sum_all = 0\n",
    "\n",
    "for j in range(0 , GT_keywords_collect_del.shape[1]) : \n",
    "    sum=0\n",
    "    num=0\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    list1 = GT_keywords_collect_del.iloc[:,j]\n",
    "    list1.dropna(inplace = True)\n",
    "    \n",
    "    for i in list1 :\n",
    "        start_time = time.time()\n",
    "        df = GT.GT_1mon(i,'')\n",
    "        end_time = time.time()\n",
    "        data = pd.concat([data,df],axis = 1)   \n",
    "        data = pd.DataFrame(data.mean(axis = 1))\n",
    "        data.columns = [columns[j]]\n",
    "\n",
    "        num+=1\n",
    "        sum+=round(end_time - start_time, 6)\n",
    "        print(\"Already Done : \"+'{}'.format(round(num,0)))\n",
    "    #data.reset_index(inplace = True)\n",
    "    data_all = pd.concat( [data_all , data] , axis = 1)\n",
    "    print(\"*****This One Done*****\")\n",
    "    total_time = time.strftime(\"%H:%M:%S\", time.gmtime( float(sum) ))\n",
    "    print(\"This Takes \" + total_time)\n",
    "    time.sleep(3)\n",
    "    \n",
    "end_time_all = time.time()    \n",
    "sum_all+=round(end_time_all - start_time_all, 6)\n",
    "print(\"*****ALL DONE*****\")\n",
    "total_time_all = time.strftime(\"%H:%M:%S\", time.gmtime( float(sum_all) ))\n",
    "print(\"All Take \"+total_time_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
